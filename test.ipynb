{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6e46f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:44<00:00,  3.17s/ba]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[保存] 原始 train split 已导出：code_contests_train_full.parquet\n",
      "[保存] 筛选并重组后的数据已导出：code_contests_train_filtered.parquet\n",
      "[统计] 筛选后样本总数：6502\n",
      "[统计] 难度分布（difficulty_value -> count / name）：\n",
      "   0 -> 1685 / UNKNOWN_DIFFICULTY\n",
      "   7 -> 1271 / A\n",
      "   8 -> 1191 / B\n",
      "   9 ->  997 / C\n",
      "  10 ->  706 / D\n",
      "  11 ->  397 / E\n",
      "  12 ->  149 / F\n",
      "  13 ->   49 / G\n",
      "  14 ->   18 / H\n",
      "  15 ->    5 / I\n",
      "  16 ->    8 / J\n",
      "  17 ->    8 / K\n",
      "  19 ->    5 / M\n",
      "  20 ->    7 / N\n",
      "  21 ->    2 / O\n",
      "  22 ->    1 / P\n",
      "  23 ->    1 / Q\n",
      "  24 ->    1 / R\n",
      "  25 ->    1 / S\n",
      "[统计] test_input 数量：最短 = 1, 最长 = 8\n",
      "\n",
      "[完成] 文件输出：\n",
      "  - 原始 train Parquet：code_contests_train_full.parquet\n",
      "  - 筛选后 Parquet：    code_contests_train_filtered.parquet\n"
     ]
    }
   ],
   "source": [
    "# pip 依赖（第一次运行需要网络）\n",
    "# 如果你的环境里已安装，可以注释掉这几行\n",
    "import sys, subprocess\n",
    "def _pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg.split(\"==\")[0])\n",
    "    except Exception:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "\n",
    "for _pkg in [\"datasets>=2.19.0\", \"pandas>=2.0.0\", \"pyarrow>=14.0.0\"]:\n",
    "    _pip_install(_pkg)\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# ========= 1) 在 Hugging Face 上加载 deepmind/code_contests 的 train split =========\n",
    "# 说明：该数据集较大，首次下载会缓存到本地\n",
    "ds = load_dataset(\"deepmind/code_contests\", split=\"train\")\n",
    "\n",
    "# ========= 2) 整个 split 转存为 Parquet（原始结构） =========\n",
    "# 优先使用 datasets 的内置导出；若不可用则退回 pandas\n",
    "full_parquet_path = \"code_contests_train_full.parquet\"\n",
    "try:\n",
    "    # 新版 datasets 支持直接导 parquet\n",
    "    ds.to_parquet(full_parquet_path)\n",
    "except Exception:\n",
    "    # 回退方案：转 pandas 再写 parquet（占内存更高）\n",
    "    ds.to_pandas().to_parquet(full_parquet_path, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(f\"[保存] 原始 train split 已导出：{full_parquet_path}\")\n",
    "\n",
    "# ========= 3) 按条件筛选 =========\n",
    "# 条件：\n",
    "# a) correct_solutions 和 incorrect_solutions 都不为空，且“Python 的答案”均至少 10 个\n",
    "#    注：数据集中 language 枚举：PYTHON(1, Python2) 与 PYTHON3(3)，这里两者都算作 Python\n",
    "# b) public_tests.input（即 test_input）不为空\n",
    "PY_LANGS = {1, 3}  # Python2 与 Python3\n",
    "\n",
    "def extract_python_codes(solutions_dict):\n",
    "    \"\"\"从 solutions/incorrect_solutions 里提取 Python 代码列表。\"\"\"\n",
    "    if not isinstance(solutions_dict, dict):\n",
    "        return []\n",
    "    langs = solutions_dict.get(\"language\", []) or []\n",
    "    sols  = solutions_dict.get(\"solution\", []) or []\n",
    "    # zip 防止长度不一致\n",
    "    out = []\n",
    "    for lang, sol in zip(langs, sols):\n",
    "        if lang in PY_LANGS and isinstance(sol, str) and sol.strip():\n",
    "            out.append(sol)\n",
    "    return out\n",
    "\n",
    "def has_nonempty_public_input(public_tests):\n",
    "    \"\"\"public_tests.input 至少有一个非空字符串。\"\"\"\n",
    "    if not isinstance(public_tests, dict):\n",
    "        return False\n",
    "    inputs = public_tests.get(\"input\", [])\n",
    "    if not isinstance(inputs, list):\n",
    "        return False\n",
    "    return any(isinstance(s, str) and s.strip() for s in inputs)\n",
    "\n",
    "filtered_rows = []\n",
    "filtered_difficulties = []     # 用于统计难度分布（不写入最终文件）\n",
    "test_input_lengths = []        # 用于统计 test_input 长度的最短与最长\n",
    "\n",
    "for ex in ds:\n",
    "    py_correct = extract_python_codes(ex.get(\"solutions\"))\n",
    "    py_incorrect = extract_python_codes(ex.get(\"incorrect_solutions\"))\n",
    "    public_tests = ex.get(\"public_tests\", {}) or {}\n",
    "    miniset_num = 5\n",
    "\n",
    "    if len(py_correct) >= miniset_num and len(py_incorrect) >= miniset_num and has_nonempty_public_input(public_tests):\n",
    "        row = {\n",
    "            # ========= 4) 仅保留并重命名你要求的字段 =========\n",
    "            \"problem\": ex.get(\"description\", \"\"),                                # 原 question/description\n",
    "            \"correct_solutions\": py_correct[:miniset_num],                                # 正确 Python 前 10\n",
    "            \"incorrect_solutions\": py_incorrect[:miniset_num],                            # 错误 Python 前 10\n",
    "            \"test_input\": public_tests.get(\"input\", []),                         # 原 public_tests.input\n",
    "            \"test_output\": public_tests.get(\"output\", []),                       # 原 public_tests.output\n",
    "        }\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "        # 仅用于统计（不写入最终 parquet）\n",
    "        filtered_difficulties.append(ex.get(\"difficulty\", 0))\n",
    "        test_input_lengths.append(len(row[\"test_input\"]))\n",
    "\n",
    "# 保存筛选后的数据\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "filtered_parquet_path = \"code_contests_train_filtered.parquet\"\n",
    "# 注意：list 列需要 pyarrow 引擎\n",
    "filtered_df.to_parquet(filtered_parquet_path, engine=\"pyarrow\", index=False)\n",
    "\n",
    "print(f\"[保存] 筛选并重组后的数据已导出：{filtered_parquet_path}\")\n",
    "\n",
    "# ========= 5) 统计并打印 =========\n",
    "# 5.1 总的 dataset 个数（筛选后）\n",
    "total_count = len(filtered_df)\n",
    "print(f\"[统计] 筛选后样本总数：{total_count}\")\n",
    "\n",
    "# 5.2 “重新存储的 problem 难度”\n",
    "#    这里打印 difficulty 字段的分布（按数值枚举统计）。若需要映射到名字，可用下方 DIFF_NAME_MAP。\n",
    "DIFF_NAME_MAP = {\n",
    "    0: \"UNKNOWN_DIFFICULTY\", 1: \"EASY\", 2: \"MEDIUM\", 3: \"HARD\", 4: \"HARDEST\", 5: \"EXTERNAL\", 6: \"EXTERNAL\",\n",
    "    # A..V -> 7..28\n",
    "    **{i: chr(ord('A') + (i - 7)) for i in range(7, 29)}\n",
    "}\n",
    "diff_counter = Counter(filtered_difficulties)\n",
    "if diff_counter:\n",
    "    print(\"[统计] 难度分布（difficulty_value -> count / name）：\")\n",
    "    for k in sorted(diff_counter.keys()):\n",
    "        name = DIFF_NAME_MAP.get(k, \"UNKNOWN\")\n",
    "        print(f\"  {k:>2} -> {diff_counter[k]:>4} / {name}\")\n",
    "else:\n",
    "    print(\"[统计] 无满足条件的数据，难度分布为空。\")\n",
    "\n",
    "# 5.3 最长和最短的 test_input 个数（public_tests.input 的条目数）\n",
    "if test_input_lengths:\n",
    "    print(f\"[统计] test_input 数量：最短 = {min(test_input_lengths)}, 最长 = {max(test_input_lengths)}\")\n",
    "else:\n",
    "    print(\"[统计] 无满足条件的数据，无法统计 test_input 长度。\")\n",
    "\n",
    "# ========== 小结 ==========\n",
    "print(\"\\n[完成] 文件输出：\")\n",
    "print(f\"  - 原始 train Parquet：{full_parquet_path}\")\n",
    "print(f\"  - 筛选后 Parquet：    {filtered_parquet_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257480a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pettingllms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
